model_config:
  hidden_units: 150
  hidden_units_mlp: 50
  fgp_size: 50
  dropout: 0.48367812441186925
  lr: 0.0001
  l2: 0.06138177190099883
  num_layers: 4
  activation: relu
  dropout_flag: False
  concat: True
  fgp: False
train_config:
  epochs: 150
  batch: 32

