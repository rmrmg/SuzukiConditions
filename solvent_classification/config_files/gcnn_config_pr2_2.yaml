model_config:
  hidden_units: 200
  hidden_units_mlp: 50
  fgp_size: 50
  dropout: 0.6501728096977945
  lr: 0.0001
  l2: 0.06473157543001008
  num_layers: 4
  activation: relu
  dropout_flag: False
  concat: True
  fgp: False
train_config:
  epochs: 150
  batch: 32

