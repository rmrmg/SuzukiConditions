model_config:
  hidden_units: 100
  hidden_units_mlp: 100
  fgp_size: 50
  dropout: 0.48587682696892476
  lr: 0.001
  l2: 0.013122802448367887
  num_layers: 3
  activation: relu
  dropout_flag: False
  concat: True
  fgp: False
train_config:
  epochs: 150
  batch: 32
